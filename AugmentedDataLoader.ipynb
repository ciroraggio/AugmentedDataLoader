{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Condizioni iniziali:\n",
    "1. Ho delle immagini nrrd di **N** pazienti\n",
    "2. Definisco una lista di **M** trasformazioni MONAI per effettuare l'augmentation di queste immagini (Rotazione, scaling eccetera)\n",
    "3. Impongo un batch size uguale a **K**\n",
    "4. Impongo che deve leggere **J** pazienti per volta dal disco\n",
    "\n",
    "## Procedimento:\n",
    "1. Leggo J pazienti tra gli N che ho, in modo casuale\n",
    "2. Applico a tutti i J pazienti le M trasformazioni, arrivando così a **(J*M)+J** immagini (J pazienti non aumentati + (J*M) aumentati)\n",
    "3. Faccio lo shuffle delle (J*M)+J immagini\n",
    "4. Fornisco i (J*M)+J  casi che ho ottenuto a blocchi di K \n",
    "5. Quando ho passato tutti i (J*M)+J pazienti a blocchi di K, leggo altri J pazienti e ripeto dal punto 2 fino a quando non ho letto tutti gli N pazienti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "from monai.data import ImageDataset\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "\"\"\"\n",
    "Inizializza il dataset e genera i batch utilizzando il metodo 'generate_batches'. \n",
    "Dopo aver creato un'istanza di AugmentedDataLoader con i parametri necessari, utilizzare il metodo generate_batches() per iterare sui batch di dati.\n",
    "    - dataset -> Dataset di tipo ImageDataset, contiene: immagini, etichette e trasformazioni sistematiche\n",
    "    - augmentation_transforms -> Lista di (M) trasformazioni MONAI per l'augmentation\n",
    "    - batch_size -> Dimensione del batch (K) ovvero i blocchi da restituire\n",
    "    - num_patients -> Numero totale di pazienti (N)\n",
    "    - subset_len -> Lunghezza del subset (J)\n",
    "    - [optional] debug_path -> se indicato, è il path dove l'utente sceglie di salvare una fetta dell'immagine, per ogni immagine dei batch restituiti \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class AugmentedDataLoader:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: ImageDataset,\n",
    "        augmentation_transforms: list,\n",
    "        batch_size: int,\n",
    "        subset_len: int,\n",
    "        debug_path: str = None,\n",
    "    ):\n",
    "        self.dataset = dataset  # Dataset di tipo ImageDataset, contiene: immagini, etichette e trasformazioni sistematiche\n",
    "        self.augmentation_transforms = augmentation_transforms  # Lista di (M) trasformazioni MONAI per l'augmentation\n",
    "        self.batch_size = batch_size  # Dimensione del batch (K)\n",
    "        self.num_patients = len(dataset.image_files)  # Numero totale di pazienti (N)\n",
    "        self.subset_len = subset_len  # Lunghezza del subset (J)\n",
    "        self.debug_path = debug_path  # se indicato, è il path dove l'utente sceglie di salvare una fetta dell'immagine, per ogni immagine dei batch restituiti\n",
    "\n",
    "    def generate_batches(self):\n",
    "        if self.dataset is None:\n",
    "            raise Exception(\"Dataset is None\")\n",
    "\n",
    "        if (\n",
    "            self.dataset.image_files\n",
    "            and self.dataset.seg_files\n",
    "            and len(self.dataset.image_files) != len(self.dataset.seg_files)\n",
    "        ):\n",
    "            raise Exception(\"The length of the images and segmentations don't match\")\n",
    "\n",
    "        # Creo una lista contenente tutti gli indici dei pazienti ed applico lo shuffle per non operare sui pazienti nello stesso ordine di arrivo\n",
    "        shuffle_patient_indices = list(range(self.num_patients))\n",
    "        random.shuffle(shuffle_patient_indices)\n",
    "\n",
    "        index = 0\n",
    "        while index < self.num_patients:\n",
    "            \"\"\"\n",
    "            ***checked_subset_len*** determina la lunghezza del subset che sarà estratto,\n",
    "            se il valore specificato dall'utente per subset_len è maggiore del numero di pazienti rimanenti,\n",
    "            allora subset_len sarà pari al numero di pazienti rimanenti, in modo da evitare di superare la lunghezza della lista dei pazienti\n",
    "            \"\"\"\n",
    "            remaining_patients = self.num_patients - index\n",
    "            checked_subset_len = min(self.subset_len, remaining_patients)\n",
    "\n",
    "            \"\"\"\n",
    "            Viene creato un subset di pazienti (che vengono scelti dalla lista di indici precedentemente mischiati) avente lunghezza J\n",
    "            \"\"\"\n",
    "            subset_indices = shuffle_patient_indices[index : index + checked_subset_len]\n",
    "            subset = torch.utils.data.Subset(self.dataset, subset_indices)\n",
    "\n",
    "            augmented_subset = []\n",
    "            for data in subset:\n",
    "                augmented_data = []\n",
    "                for transformation in self.augmentation_transforms:\n",
    "                    augmented_data.append(transformation(data[0]))\n",
    "\n",
    "                augmented_subset.append(data[0])  # Aggiungo le immagini NON aumentate\n",
    "                augmented_subset.extend(\n",
    "                    augmented_data\n",
    "                )  # Aggiungo le immagini aumentate\n",
    "\n",
    "            \"\"\"\n",
    "            Ulteriore shuffle delle (J*M)+J immagini, in questo modo riceverà immagini aumentate e non aumentate mixate\n",
    "            \"\"\"\n",
    "            full_batch_indices = torch.randperm(len(augmented_subset))\n",
    "            augmented_subset = [augmented_subset[idx] for idx in full_batch_indices]\n",
    "\n",
    "            \"\"\"\n",
    "            Creo blocchi di dimensione K\n",
    "            - range(0, len(augmented_subset), self.batch_size): \n",
    "                genera una sequenza di valori che rappresentano gli indici di inizio di ogni blocco. \n",
    "                Gli indici partono da 0 e avanzano con un passo pari a self.batch_size, fino a raggiungere la lunghezza totale di augmented_subset.\n",
    "            - augmented_subset[i:i + self.batch_size]: \n",
    "                seleziona una sotto-lista di augmented_subset che va dall'indice i fino all'indice i + self.batch_size. \n",
    "                Questo crea un blocco di immagini di dimensione self.batch_size.\n",
    "            \"\"\"\n",
    "            blocks = [\n",
    "                augmented_subset[i : i + self.batch_size]\n",
    "                for i in range(0, len(augmented_subset), self.batch_size)\n",
    "            ]\n",
    "            \n",
    "            image_count = 0\n",
    "            for block in blocks:\n",
    "                \"\"\"\n",
    "                Restituisco i blocchi di dimensione K.\n",
    "                Per ogni blocco, viene creato un tensore batch utilizzando la funzione stack di torch che concatena i tensori all'interno del blocco lungo la dimensione 0,\n",
    "                creando così un unico tensore che rappresenta un batch di immagini.\n",
    "                Operatore yield per mantenere lo stato della funzione tra le chiamate.\n",
    "                \"\"\"\n",
    "                if self.debug_path:\n",
    "                    for i, data in enumerate(block):\n",
    "                        image = data[0]\n",
    "                        central_slice = image[image.shape[0] // 2]  # Estraggo la fetta centrale sul primo canale\n",
    "                        normalized_slice = (central_slice - central_slice.min()) / (central_slice.max() - central_slice.min())\n",
    "                        debug_image_path = os.path.join(self.debug_path, f\"augmented_image_{image_count}.png\")\n",
    "                        vutils.save_image(normalized_slice, debug_image_path)\n",
    "                        image_count += 1\n",
    "\n",
    "                        \n",
    "                block = [data.float() for data in block]  # Conversione dei tensori delle immagini a float32\n",
    "                batch = torch.stack(block)\n",
    "                yield batch\n",
    "\n",
    "            \"\"\"\n",
    "            Dopo aver passato tutti i (J*M)+J pazienti a blocchi di K, incremento l'indice e riparto per leggere altri J pazienti\n",
    "            \"\"\"\n",
    "            index += checked_subset_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totale immagini: 3\n",
      "Totale trasformazioni: 2\n",
      "Grandezza batch richiesta: 2\n",
      "Blocchi ricevuti: 5\n"
     ]
    }
   ],
   "source": [
    "from monai.transforms import Rotate, Compose, Resize\n",
    "\n",
    "# ImageDataset params\n",
    "images_to_transform = [\n",
    "    \"./benchmark/data/PDDCA-1.4.1_part1/0522c0001/img.nrrd\",\n",
    "    \"./benchmark/data/PDDCA-1.4.1_part1/0522c0002/img.nrrd\",\n",
    "    \"./benchmark/data/PDDCA-1.4.1_part1/0522c0003/img.nrrd\",\n",
    "    # \"./benchmark/data/PDDCA-1.4.1_part1/0522c0009/img.nrrd\",\n",
    "    # \"./benchmark/data/PDDCA-1.4.1_part1/0522c0013/img.nrrd\",\n",
    "]\n",
    "\n",
    "labels_to_transform = [\n",
    "    \"./benchmark/data/PDDCA-1.4.1_part1/0522c0001/structures/Parotid_L.nrrd\",\n",
    "    \"./benchmark/data/PDDCA-1.4.1_part1/0522c0002/structures/Parotid_L.nrrd\",\n",
    "    \"./benchmark/data/PDDCA-1.4.1_part1/0522c0003/structures/Parotid_L.nrrd\",\n",
    "    # \"./benchmark/data/PDDCA-1.4.1_part1/0522c0009/structures/BrainStem.nrrd\",\n",
    "    # \"./benchmark/data/PDDCA-1.4.1_part1/0522c0013/structures/BrainStem.nrrd\",\n",
    "]\n",
    "each_image_trans = Compose([Resize([74,74,74])])\n",
    "\n",
    "# AugmentedDataLoader params\n",
    "augmentation_transforms = [\n",
    "    Rotate(angle=35),\n",
    "    Rotate(angle=61),\n",
    "]\n",
    "batch_size = 2\n",
    "num_patients = len(images_to_transform)\n",
    "dataset = ImageDataset(image_files=images_to_transform, labels=labels_to_transform, transform=each_image_trans)\n",
    "debug_path='./benchmark/data/debug_path_test'\n",
    "data_loader = AugmentedDataLoader(dataset, augmentation_transforms, batch_size, 2, debug_path) # per debug\n",
    "# data_loader = AugmentedDataLoader(dataset, augmentation_transforms, batch_size, 2) # no debug\n",
    "\n",
    "blocks = 0\n",
    "for batch_data in data_loader.generate_batches():\n",
    "    # inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "    try:\n",
    "        # print(f\"Batch data shape: {batch_data.shape}\")\n",
    "        inputs, labels = (batch_data[0], None) if len(batch_data) == 1 else batch_data\n",
    "        blocks+=1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Errore: {e}\")\n",
    "\n",
    "print(f\"Totale immagini: {num_patients}\")\n",
    "print(f\"Totale trasformazioni: {len(augmentation_transforms)}\")\n",
    "print(f\"Grandezza batch richiesta: {batch_size}\")\n",
    "print(f\"Blocchi ricevuti: {blocks}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
