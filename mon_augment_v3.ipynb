{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Condizioni iniziali:\n",
    "1. Ho delle immagini nrrd di **N** pazienti\n",
    "2. Definisco una lista di **M** trasformazioni MONAI per effettuare l'augmentation di queste immagini (Rotazione, scaling eccetera)\n",
    "3. Impongo un batch size uguale a **K**\n",
    "4. Impongo che deve leggere **J** pazienti per volta dal disco\n",
    "\n",
    "## Procedimento:\n",
    "1. Leggo J pazienti tra gli N che ho, in modo casuale\n",
    "2. Applico a tutti i J pazienti le M trasformazioni, arrivando così a **(J*M)+J** immagini (J pazienti non aumentati + (J*M) aumentati)\n",
    "3. Faccio lo shuffle delle (J*M)+J immagini\n",
    "4. Fornisco i (J*M)+J  casi che ho ottenuto a blocchi di K \n",
    "5. Quando ho passato tutti i (J*M)+J pazienti a blocchi di K, leggo altri J pazienti e ripeto dal punto 2 fino a quando non ho letto tutti gli N pazienti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai.transforms import Resize\n",
    "from monai.data import ImageDataset\n",
    "\n",
    "\"\"\"\n",
    "Inizializza il dataset e genera i batch utilizzando il metodo 'generate_batches'. \n",
    "Dopo aver creato un'istanza di DataGenerator con i parametri necessari, utilizzare il metodo generate_batches() per iterare sui batch di dati.\n",
    "    - images_to_transform -> Lista delle immagini di (N) pazienti\n",
    "    - augmentation_transforms -> Lista di (M) trasformazioni MONAI per l'augmentation\n",
    "    - batch_size -> Dimensione del batch (K) ovvero i blocchi da restituire\n",
    "    - num_patients -> Numero totale di pazienti (N)\n",
    "\"\"\"\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self, images_to_transform, augmentation_transforms, batch_size, target_size=(512,512,1)):\n",
    "        self.images_to_transform = images_to_transform  # Lista delle immagini di (N) pazienti\n",
    "        self.augmentation_transforms = augmentation_transforms  # Lista di (M) trasformazioni MONAI per l'augmentation\n",
    "        self.batch_size = batch_size  # Dimensione del batch (K)\n",
    "        self.num_patients = len(images_to_transform)  # Numero totale di pazienti (N)\n",
    "        self.target_size = target_size\n",
    "        self.dataset = None\n",
    "\n",
    "    def initialize_dataset(self):\n",
    "        resize_transform = Resize(self.target_size)\n",
    "        self.dataset = ImageDataset(image_files=self.images_to_transform, transform=resize_transform)\n",
    "\n",
    "    def generate_batches(self):\n",
    "        if self.dataset is None:\n",
    "            self.initialize_dataset()\n",
    "\n",
    "        \"\"\"\n",
    "        Vengono generati indici casuali per selezionare un sottoinsieme di (J) pazienti dal numero totale di pazienti (N). \n",
    "        \"\"\"\n",
    "        indices = torch.randperm(self.num_patients)\n",
    "        index = 0\n",
    "\n",
    "        while index < self.num_patients:\n",
    "            \"\"\"\n",
    "            Nel caso in cui la somma dell'indice corrente (index) e la dimensione del batch (self.batch_size) sia minore del numero totale di pazienti (self.num_patients), \n",
    "            allora end_index sarà indice corrente + dimensione del batch.\n",
    "            Se invece la somma supera il numero totale di pazienti, allora end_index sarà il numero totale di pazienti stesso.\n",
    "            In questo modo, è sicuro che il subset di pazienti non superi mai il numero totale di pazienti disponibili.\n",
    "            \"\"\"\n",
    "            end_index = min(index + self.batch_size, self.num_patients)\n",
    "\n",
    "            \"\"\"\n",
    "            Viene creato un subset di J pazienti selezionando gli indici generati casualmente.\n",
    "            \"\"\"\n",
    "            subset_indices = indices[index:end_index]\n",
    "            subset = torch.utils.data.Subset(self.dataset, subset_indices)\n",
    "\n",
    "            \"\"\"\n",
    "            Applico a tutti i J pazienti le M trasformazioni, per avere (J*M)+J immagini\n",
    "            \"\"\"\n",
    "            augmented_subset = []\n",
    "            for data in subset:\n",
    "                augmented_data = []\n",
    "                for transformation in self.augmentation_transforms:\n",
    "                    augmented_data.append(transformation(data))\n",
    "                augmented_subset.append(data)  # Aggiungo le immagini NON aumentate\n",
    "                augmented_subset.extend(augmented_data)  # Aggiungo le immagini aumentate\n",
    "\n",
    "            # Shuffle delle (J*M)+J immagini\n",
    "            indices = torch.randperm(len(augmented_subset))\n",
    "            augmented_subset = [augmented_subset[idx] for idx in indices]\n",
    " \n",
    "            \"\"\"\n",
    "            Creo blocchi di dimensione K\n",
    "            - range(0, len(augmented_subset), self.batch_size): \n",
    "                genera una sequenza di valori che rappresentano gli indici di inizio di ogni blocco. \n",
    "                Gli indici partono da 0 e avanzano con un passo pari a self.batch_size, fino a raggiungere la lunghezza totale di augmented_subset.\n",
    "            - augmented_subset[i:i + self.batch_size]: \n",
    "                seleziona una sotto-lista di augmented_subset che va dall'indice i fino all'indice i + self.batch_size. \n",
    "                Questo crea un blocco di immagini di dimensione self.batch_size.\n",
    "            \"\"\"\n",
    "            blocks = [augmented_subset[i:i + self.batch_size] for i in range(0, len(augmented_subset), self.batch_size)]\n",
    "\n",
    "            for block in blocks:\n",
    "                \"\"\"\n",
    "                Restituisco i blocchi di dimensione K.\n",
    "                Per ogni blocco, viene creato un tensore batch utilizzando la funzione stack di torch che concatena i tensori all'interno del blocco lungo la dimensione 0, \n",
    "                creando così un unico tensore che rappresenta un batch di immagini.\n",
    "                Operatore yield per mantenere lo stato della funzione tra le chiamate. \n",
    "                \"\"\"\n",
    "                batch = torch.stack(block)\n",
    "                yield batch\n",
    "\n",
    "            \"\"\"\n",
    "            Dopo aver passato tutti i (J*M)+J pazienti a blocchi di K, incremento l'indice e riparto per leggere altri J pazienti\n",
    "            \"\"\"\n",
    "            index += self.batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totale immagini: 5\n",
      "Totale trasformazioni: 2\n",
      "Grandezza batch richiesta: 2\n",
      "Blocchi ricevuti: 8\n"
     ]
    }
   ],
   "source": [
    "from monai.transforms import Rotate\n",
    "\n",
    "images_to_transform = [\n",
    "    \"./data/PDDCA-1.4.1_part1/0522c0001/img.nrrd\",\n",
    "    \"./data/PDDCA-1.4.1_part1/0522c0002/img.nrrd\",\n",
    "    \"./data/PDDCA-1.4.1_part1/0522c0003/img.nrrd\",\n",
    "    \"./data/PDDCA-1.4.1_part1/0522c0009/img.nrrd\",\n",
    "    \"./data/PDDCA-1.4.1_part1/0522c0013/img.nrrd\",\n",
    "]\n",
    "\n",
    "augmentation_transforms = [\n",
    "    Rotate(angle=35),\n",
    "    Rotate(angle=61),\n",
    "]\n",
    "batch_size = 2\n",
    "num_patients = len(images_to_transform)\n",
    "\n",
    "data_generator = DataGenerator(images_to_transform, augmentation_transforms, batch_size)\n",
    "blocks = 0\n",
    "for batch_data in data_generator.generate_batches():\n",
    "    # inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "    try:\n",
    "        # print(f\"Batch data shape: {batch_data.shape}\")\n",
    "        inputs, labels = (batch_data[0], None) if len(batch_data) == 1 else batch_data\n",
    "        blocks+=1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Errore: {e}\")\n",
    "\n",
    "print(f\"Totale immagini: {num_patients}\")\n",
    "print(f\"Totale trasformazioni: {len(augmentation_transforms)}\")\n",
    "print(f\"Grandezza batch richiesta: {batch_size}\")\n",
    "print(f\"Blocchi ricevuti: {blocks}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
