{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Condizioni iniziali:\n",
    "1. Ho delle immagini nrrd di **N** pazienti\n",
    "2. Definisco una lista di **M** trasformazioni MONAI per effettuare l'augmentation di queste immagini (Rotazione, scaling eccetera)\n",
    "3. Impongo un batch size uguale a **K**\n",
    "4. Impongo che deve leggere **J** pazienti per volta dal disco\n",
    "\n",
    "## Procedimento:\n",
    "1. Leggo J pazienti tra gli N che ho, in modo casuale\n",
    "2. Applico a tutti i J pazienti le M trasformazioni, arrivando così a **(J*M)+J** immagini (J pazienti non aumentati + (J*M) aumentati)\n",
    "3. Faccio lo shuffle delle (J*M)+J immagini\n",
    "4. Fornisco i (J*M)+J  casi che ho ottenuto a blocchi di K \n",
    "5. Quando ho passato tutti i (J*M)+J pazienti a blocchi di K, leggo altri J pazienti e ripeto dal punto 2 fino a quando non ho letto tutti gli N pazienti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai.transforms import Compose\n",
    "from monai.data import ImageDataset\n",
    "\n",
    "\"\"\"\n",
    "Inizializza il dataset e genera i batch utilizzando il metodo 'generate_batches'. \n",
    "Dopo aver creato un'istanza di DataGenerator con i parametri necessari, utilizzare il metodo generate_batches() per iterare sui batch di dati.\n",
    "    - images_to_transform -> Lista delle immagini di (N) pazienti\n",
    "    - augmentation_transforms -> Lista di (M) trasformazioni MONAI per l'augmentation\n",
    "    - batch_size -> Dimensione del batch (K) ovvero i blocchi da restituire\n",
    "    - num_patients -> Numero totale di pazienti (N)\n",
    "\"\"\"\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self, images_to_transform, augmentation_transforms, batch_size):\n",
    "        self.images_to_transform = images_to_transform  # Lista delle immagini di (N) pazienti\n",
    "        self.augmentation_transforms = augmentation_transforms  # Lista di (M) trasformazioni MONAI per l'augmentation\n",
    "        self.batch_size = batch_size  # Dimensione del batch (K)\n",
    "        self.num_patients = len(images_to_transform)  # Numero totale di pazienti (N)\n",
    "        self.dataset = None\n",
    "\n",
    "    def initialize_dataset(self):\n",
    "        train_transforms = Compose([Compose(self.augmentation_transforms)])\n",
    "        self.dataset = ImageDataset(image_files=self.images_to_transform, transform=train_transforms)\n",
    "\n",
    "    def generate_batches(self):\n",
    "        if self.dataset is None:\n",
    "            self.initialize_dataset()\n",
    "\n",
    "        \"\"\"\n",
    "        Vengono generati indici casuali per selezionare un sottoinsieme di (J) pazienti dal numero totale di pazienti (N). \n",
    "        \"\"\"\n",
    "        indices = torch.randperm(self.num_patients)\n",
    "        index = 0\n",
    "\n",
    "        while index < self.num_patients:\n",
    "            \"\"\"\n",
    "            Nel caso in cui la somma dell'indice corrente (index) e la dimensione del batch (self.batch_size) sia minore del numero totale di pazienti (self.num_patients), \n",
    "            allora end_index sarà indice corrente + dimensione del batch.\n",
    "            Se invece la somma supera il numero totale di pazienti, allora end_index sarà il numero totale di pazienti stesso.\n",
    "            In questo modo, è sicuro che il subset di pazienti non superi mai il numero totale di pazienti disponibili.\n",
    "            \"\"\"\n",
    "            end_index = min(index + self.batch_size, self.num_patients)\n",
    "\n",
    "            \"\"\"\n",
    "            Viene creato un subset di J pazienti selezionando gli indici generati casualmente.\n",
    "            \"\"\"\n",
    "            subset_indices = indices[index:end_index]\n",
    "            subset = torch.utils.data.Subset(self.dataset, subset_indices)\n",
    "\n",
    "            \"\"\"\n",
    "            Applico a tutti i J pazienti le M trasformazioni, per avere (J*M)+J immagini\n",
    "            \"\"\"\n",
    "            augmented_subset = []\n",
    "            for data in subset:\n",
    "                augmented_data = []\n",
    "                for transformation in self.augmentation_transforms:\n",
    "                    augmented_data.append(transformation(data))\n",
    "                augmented_subset.append(data)  # Aggiungo le immagini non aumentate\n",
    "                augmented_subset.extend(augmented_data)  # Aggiungo le immagini aumentate\n",
    "\n",
    "            # Shuffle delle (J*M)+J immagini\n",
    "            indices = torch.randperm(len(augmented_subset))\n",
    "            augmented_subset = [augmented_subset[idx] for idx in indices]\n",
    " \n",
    "            \"\"\"\n",
    "            Creo blocchi di dimensione K\n",
    "            - range(0, len(augmented_subset), self.batch_size): \n",
    "                genera una sequenza di valori che rappresentano gli indici di inizio di ogni blocco. \n",
    "                Gli indici partono da 0 e avanzano con un passo pari a self.batch_size, fino a raggiungere la lunghezza totale di augmented_subset.\n",
    "            - augmented_subset[i:i + self.batch_size]: \n",
    "                seleziona una sotto-lista di augmented_subset che va dall'indice i fino all'indice i + self.batch_size. \n",
    "                Questo crea un blocco di immagini di dimensione self.batch_size.\n",
    "            \"\"\"\n",
    "            blocks = [augmented_subset[i:i + self.batch_size] for i in range(0, len(augmented_subset), self.batch_size)]\n",
    "\n",
    "            for block in blocks:\n",
    "                \"\"\"\n",
    "                Restituisco i blocchi di dimensione K.\n",
    "                Per ogni blocco, viene creato un tensore batch utilizzando la funzione stack di torch che concatena i tensori all'interno del blocco lungo la dimensione 0, \n",
    "                creando così un unico tensore che rappresenta un batch di immagini.\n",
    "                Operatore yield per mantenere lo stato della funzione tra le chiamate. \n",
    "                \"\"\"\n",
    "                batch = torch.stack(block)\n",
    "                yield batch\n",
    "\n",
    "            \"\"\"\n",
    "            Dopo aver passato tutti i (J*M)+J pazienti a blocchi di K, incremento l'indice e riparto per leggere altri J pazienti\n",
    "            \"\"\"\n",
    "            index += self.batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'monai' has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     20\u001b[0m blocks \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfor\u001b[39;00m batch_data \u001b[39min\u001b[39;00m data_generator\u001b[39m.\u001b[39mgenerate_batches():\n\u001b[0;32m     22\u001b[0m     \u001b[39m# inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     inputs, labels \u001b[39m=\u001b[39m batch_data[\u001b[39m0\u001b[39m], batch_data[\u001b[39m1\u001b[39m]\n\u001b[0;32m     24\u001b[0m     blocks\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[7], line 55\u001b[0m, in \u001b[0;36mDataGenerator.generate_batches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[39mApplico a tutti i J pazienti le M trasformazioni, per avere (J*M)+J immagini\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m augmented_subset \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 55\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m subset:\n\u001b[0;32m     56\u001b[0m     augmented_data \u001b[39m=\u001b[39m []\n\u001b[0;32m     57\u001b[0m     \u001b[39mfor\u001b[39;00m transformation \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugmentation_transforms:\n",
      "File \u001b[1;32mc:\\Users\\CiroRaggio\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[1;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[1;32mc:\\Users\\CiroRaggio\\anaconda3\\lib\\site-packages\\monai\\data\\image_dataset.py:105\u001b[0m, in \u001b[0;36mImageDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39m# load data and optionally meta\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_only:\n\u001b[1;32m--> 105\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloader(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimage_files[index])\n\u001b[0;32m    106\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseg_files \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m         seg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseg_files[index])\n",
      "File \u001b[1;32mc:\\Users\\CiroRaggio\\anaconda3\\lib\\site-packages\\monai\\transforms\\io\\array.py:275\u001b[0m, in \u001b[0;36mLoadImage.__call__\u001b[1;34m(self, filename, reader)\u001b[0m\n\u001b[0;32m    273\u001b[0m img_array: NdarrayOrTensor\n\u001b[0;32m    274\u001b[0m img_array, meta_data \u001b[39m=\u001b[39m reader\u001b[39m.\u001b[39mget_data(img)\n\u001b[1;32m--> 275\u001b[0m img_array \u001b[39m=\u001b[39m convert_to_dst_type(img_array, dst\u001b[39m=\u001b[39;49mimg_array, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    276\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(meta_data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    277\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`meta_data` must be a dict.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\CiroRaggio\\anaconda3\\lib\\site-packages\\monai\\utils\\type_conversion.py:359\u001b[0m, in \u001b[0;36mconvert_to_dst_type\u001b[1;34m(src, dst, dtype, wrap_sequence, device, safe)\u001b[0m\n\u001b[0;32m    357\u001b[0m copy_meta \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    358\u001b[0m output_type: Any\n\u001b[1;32m--> 359\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dst, monai\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39mMetaTensor):\n\u001b[0;32m    360\u001b[0m     output_type \u001b[39m=\u001b[39m monai\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mMetaTensor\n\u001b[0;32m    361\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(src, monai\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mMetaTensor):\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'monai' has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "from monai.transforms import Zoom, Rotate, Resize\n",
    "\n",
    "images_to_transform = [\n",
    "    \"./data/PDDCA-1.4.1_part1/0522c0001/img.nrrd\",\n",
    "    \"./data/PDDCA-1.4.1_part1/0522c0002/img.nrrd\",\n",
    "    \"./data/PDDCA-1.4.1_part1/0522c0003/img.nrrd\",\n",
    "    \"./data/PDDCA-1.4.1_part1/0522c0009/img.nrrd\",\n",
    "    \"./data/PDDCA-1.4.1_part1/0522c0013/img.nrrd\",\n",
    "]\n",
    "\n",
    "augmentation_transforms = [\n",
    "    Resize(spatial_size=(512,512,1)),\n",
    "    Rotate(angle=35),\n",
    "]\n",
    "batch_size = 2\n",
    "num_patients = len(images_to_transform)\n",
    "\n",
    "data_generator = DataGenerator(images_to_transform, augmentation_transforms, batch_size)\n",
    "device = 0\n",
    "blocks = 0\n",
    "for batch_data in data_generator.generate_batches():\n",
    "    # inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "    inputs, labels = batch_data[0], batch_data[1]\n",
    "    blocks+=1\n",
    "\n",
    "print(f\"Totale immagini: {num_patients}\")\n",
    "print(f\"Grandezza batch richiesta: {batch_size}\")\n",
    "print(f\"Blocchi ricevuti: {blocks}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
